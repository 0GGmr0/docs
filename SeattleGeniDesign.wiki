= !SeattleGeni Design Document/Proposal =

This is a proposal for the rewrite SeattleGeni. Feedback welcome (e.g. comments here, to jsamuel, or to the list).

[[TOC(inline)]]

----

== Design Goals ==

  * Greater understandability and maintainability.
    * Current design is more difficult than necessary for new people to understand.
  * Easier testing.
    * Current design's lack of modularity makes testing difficult.
  * Better logging.
    * Design not only needs to incorporate better logging, but needs to allow easy future addition of logging.
  * Eliminate race conditions.
    * Current implementation has various race conditions related to database access.
  * Improve security.
    * Minimize the impact of website/webserver compromise.

----

== New Design Plan ==

At a high level, the idea will be to:
  * Take the existing concept of a separate backend server and extend it to handling most data-modifying and node-modifying actions.
  * Implement an explicit queue of actions in the backend server.
  * Move all keys to a separate keyserver.
  * Limit the website's role to mostly very simple data access, minimally-privileged keyserver requests, and interacting with the backend server.

=== Website ===

[[Image(geniportal_v3_website.gif)]]

  * End clients communicate with the website through either XML-RPC or HTTP.
  * The request's authorization is checked (e.g. ensure valid session for HTTP) and
    the request is then sent through the Controller Interface.
  * The Controller then processes the request based on the type of request.
    * A request for a user to acquire/release vessels will be sent to the backend through
      the Backend API.
    * A request to obtain the user's public or private key, or to delete the user's
      private key, will go through the Keyserver Low-Auth API (the only keyserver API calls that
      the website has sufficient privileges to execute).
    * Certain safe and simple database needs may go directly to the database through a
      Main DB Website API. This prevents the need to send every potential query through the
      backed server, which may add unnecessary complication and performance impacts.
      At a minimum this would include reading and updating user account information that could
      not interfere with backend operations.
      * This is called the "Main DB Website API" mostly just to emphasize that only a few
        direct database actions will be performed by the Controller.

Note that the Website could just do more/everything through the backend server, but that might result in
excessive communication to fulfill simple website requests and clutter the backend interface.
This is open for debate and change. For example, it
might be worthwhile to require user private key reading (for download by the user) to go through the
backend server, but this may be extra indirection for little benefit.

=== Backend ===

[[Image(geniportal_v3_backend.gif)]]

The Backend performs fundamentally the same purpose as the current backend implementation. It
provides a means for other code to hand off non-trivial tasks to a process that can ensure the
tasks are done correctly and efficiently (proper ordering, mutual exclusion for shared data
access, safely parallelized operations).

The Backend maintains an explicit Queue of tasks which are stored in a database. The tasks
in the Queue are processed by a thread called the Queue Runner.

The Backend exposes a private XML-RPC interface for use by other code within the system,
including the Website and Polling Daemons.
  * Requests that can be safely fulfilled without risk of data access conflicts can be fulfilled immediately without being entered in the Queue.
    * Such requests are inherently synchronous requests.
  * Requests that cannot be safely fulfilled without risk of data access conflicts are entered in the Queue.
    * Such requests are inherently asynchronous requests, but the Backend XML-RPC Interface can also provide a synchronous interface to any such action.
      * For these requests, a task_id is assigned (the id in the Queue).
      * For XML-RPC requests that are intended to be asynchronous requests, the task_id is returned and can be used to query the status of the task later.
      * For XML-RPC requests that are intended to be synchronous, the response can block until the queued task has been performed.

The method by which the Backend determines that a privileged request is authorized is not specified here for the moment. It may be as simple as a passphrase included with the request. Other security measures to be taken include only accepting requests from known IPs. 

=== Polling Daemons ===

[[Image(geniportal_v3_polling_daemons.gif)]]

Polling Daemons are any processes or scripts that perform general monitoring of nodes
as well as node state transition functionality. These processes communicate with nodes
through the Node Manager API. 

=== Keyserver ===

[[Image(geniportal_v3_keyserver.gif)]]

The Keyserver exposes a private XML-RPC interface for use by other code within the system,
including the website and the Node Manager API. 

The Keyserver maintains all keys. No keys are stored in any other part of the system. When
a public and/or private key needs to be stored, it is stored in the keyserver and a unique
id can then be communicated to the Keyserver XML-RPC Interface to perform actions with the key.

Actions performed by the Keyserver include:
  * Store/delete/retrieve public/private key.
  * Sign data with a private key.
  * Verify data signature with a public key.

Only a few actions will be authorized to be performed when the request comes from the Website.
The method by which the Keyserver determines that a privileged request is authorized is not
specified here for the moment. It may be as simple as a passphrase included with the request. Other security
measures to be taken include only accepting requests from known IPs.

=== Node Manager API ===

The Node Manager API internally makes use of the Keyserver API in order to, for example, obtain
signed data to be communicated to nodes.

----

== Logging ==

Logging will be available in multiple ways:
  * Request/Response available via [http://docs.djangoproject.com/en/dev/topics/http/middleware/ django middleware].
  * Logging at the controller interface will be possible (allows logging requests/response, recording time, etc. independent of frontend -- though much of this may be taken care of by the backend when processing the queue).
  * Use of the python logger module (no calls to "print", ever).
  * Email critical errors to developers (include request/response information).
  * As the queue maintained by the backend will not be deleting processed requests but rather only marking them as completed with their resulting information, this will provide a log in itself.

Ultimately, various logged information should be summarized and available through a website so that the status of the site can be easily monitored. This would include details of exceptions, number of types of requests, average request times for different requests, etc. A summarization/visualization of this data helps to identify logic bugs. For example, there may be no critical exceptions happening but an unusually high percentage of vessel acquisition requests are not able to be fulfilled. Such a situation would be better seen through a summary of results of calls that pass through the controller interface rather than waiting for the bug to be noticed directly.
 
----

== Testing ==

  * Unit tests at various locations:
    * frontends (using [http://docs.djangoproject.com/en/dev/topics/testing/ django test framework])
    * controller interface
    * keyserver
    * backend
    * nodemanager api
  * Test data:
    * make use of [http://docs.djangoproject.com/en/dev/topics/testing/#fixture-loading fixtures in django]
  * Dependency injection to increase testability using mock objects:
    * at least in databases and the Node Manager API so that, for example, other functions that ultimately result in node communication can be tested without actual node communication.

----

== Models ==

The details of the models (database schemas) are below.

Note that with the decision to move most work away from the website, there is a very strong argument for using a different ORM besides django's. This is especially true with the intention to use multiple databases (at least a main database and a keyserver database -- though these probably won't/shouldn't be being used from within the same application, the general idea of going forward in a way that will easily allow using multiple, separate database within the same application might save problems later). One option for such an ORM to use instead of django's is SQLAlchemy. One side effect of a decision to use a non-django ORM would likely be the loss of use of the django admin data views. This would just mean a bit more work to write the parts of that which are needed.

=== Main Database ===

  * User
    * purpose:
      * A User record represents a !SeattleGeni user.
    * fields:
      * djangouser
        * links this record to the django user record
      * port
      * affiliation
      * key_id
      * donor_key_id
    * notes
      * For efficiency reasons, additional fields may be added to keep cached values for the amount of resources the user has donated and has acquired, rather than requiring calculating this information on demand.

  * Node
    * purpose:
      * A Node record represents an individual nodemanager.
    * fields:
      * key_id (used only for the public key which is the node's identifier)
      * ip
      * port
      * date_added
      * last_heard
      * version
      * active
      * owner_key_id (this is !SeattleGeni's owner key for this node)
    * notes
      * The subnet will be calculated as needed rather than stored unless the database impact is too high. If it needs to be saved, it will be an indexed string field. (The current implementation as the concatenated first three octets without periods looks flawed unless I'm reading it wrong).

  * Donation
    * purpose:
      * A Donation record represents the resources a user has donated from a single node.
    * fields:
      * node (foreign key to nodes table)
      * donor (foreign key to the users table)
      * status
        * This field will be used, if necessary, to indicate steps in the process of setting up a donation's resources for use (which, for now, would be creating vessels on the corresponding node using this donation's resources).
    * notes
      * In the future, there may be more than one donor of a node and so multiple Donation records for a single node but each with different donors. For now it will be used as just one donation record per node record.

  * !DonationResource
    * purpose:
      * A !DonationResource record represents the type and amount of an individual resource that is part of a donation. 
    * fields:
      * donation (foreign key to donations table)
      * type
        * enum: "resource" or "call"
        * if type is "resource", then either the int_val or float_val field will be filled in.
        * if type is "call", it is assumed to be "allow" by the fact this it is in here.
      * name
        * these will generally correspond to names of resources/calls in resource files, such as "loopsend", "connport", or "log.writelines"
      * int_val
      * float_val

  * Vessel
    * purpose:
      * A vessel record represents a vessel that !SeattleGeni has setup on a node. Note that this is '''not''' tied to an individual donation of resources from that node.
    * fields:
      * node (foreign key to the nodes table)
      * name
      * status
        * there is a documented [https://seattle.cs.washington.edu/wiki/NodeManagerDesign#NodeManagerInterface list of possible statuses]
      * extra_vessel (whether this is an 'extra vessel')
      * acquired_by_user (foreign key to the users table)
        * if this vessel has been acquired by a user, this is the user who acquired it
      * date_acquired
      * date_expires
    * notes:
      * when we want to begin tracking individual resources in each vessel, we can create a !VesselResource table like the !DonationResource table.

  * !VesselPort
    * purpose:
      * A !VesselPort record represents a port that is assigned to a vessel. A single vessel can have multiple ports assigned to it (multiple !VesselPort records).
    * fields:
      * vessel (foreign key to vessels table)
      * port

  * !VesselUserAccessMap
    * purpose:
      * A !VesselUserAccessMap record represents user access to vessels. This is a many-to-many relationship. The user who acquired the vessel will always have a mapping to that vessel. In the future when additional users can be added to a Vessel through !SeattleGeni, the additional users would have records here.
    * fields:
      * vessel (foreign key to vessels table)
      * user (foreign key to users table)
      * date_added

  * Queue
    * purpose:
      * Items in the queue represent tasks for the backend.
      * Note: the table will be called "queue" --- that's not the name of each record. This model is more of a table description than a data item description.
    * fields:
      * id
      * source
        * the client application that added this item to the queue (e.g. website, node transition script, other)
      * status
        * enum: 'New', '!InProgress', 'Completed', 'Failed'
      * error_code
      * error_message
      * date_added
      * date_started
      * date_ended
      * task_type (foreign key to !QueueTaskType table)
      * [a field for each piece of information that is needed by each task type]
      * [a field for each piece of information that is returned by each task type]
    * notes
      * another option besides including additional fields for each parameter and return value would be to create a separate table for each task type and have only the necessary fields in each table. That complicates the sql, though, when trying to aggregate data. This will be reconsidered when implementing if clarity is greatly enhanced by doing so. In general, I think this would be referred to as "disjoint subtypes" or "polymorphism in databases" (as in, the queue table would be a base type and the other tables would be the subtypes). Depending on the ORM used, functionality to support this easily could already be supported (e.g. SQLAlchemy's "with_polymorphism").
      * depending on the exact types of tasks that get defined, it seems likely that this table could easily grow by 1000 records a day when seattle gains some momentum. 10k a day might not even be out of the question. So, we're looking at 400k+ records a year. I don't expect this to be a problem. Performance shouldn't suffer with less than a few million records (aside from any aggregation/statistics queries that may be being run administratively). When it becomes necessary, an archiver script can be run to move records from the live queue table to a separate archive queue table.

  * !QueueTaskType
    * purpose:
      * A !QueueTaskType represents a type of task in the queue. The reason an enum field isn't used in Queue is because it is likely that new types of tasks will be added and it will be easier and faster to make these changes with this being a joined table rather than an enum. The performance loss shouldn't be a concern except in cases of aggregating queue data, which would be more of an administrative task than a normal operation within the system.
    * fields:
      * id
      * type
        * one record each for values such as '!AcquireVessels', '!ReleaseVessels', '!ChangeUserKey', '!AddUserToVessels', '!SetupDonatedResources', '!DisableNode', '!EnableNode', ...
        * using the names '!AcquireVessels' and '!ReleaseVessels' as there may be a reason to have separate '!AcquireResources' and '!ReleaseResources' types later on that are more than just simple vessel acquisition.

=== Keyserver Database ===

  * Key
    * purpose:
      * A Key record represents a public/private key pair. The private key is optional (whether it should be there depends on the purpose of this stored key).
    * fields:
      * id
      * pubkey
      * privkey
      * allow_unprivileged
        * flag to indicate whether this key is accessible to unprivileged client applications (e.g. the website).
        * if an unprivileged client requests this key (or, possibly just the private key/signing services), the request would be rejected if this flag is not set.

=== Model Notes ===

  * '''Indexing'''
    * The current database schema does not appear to make use of additional indexes for performance.
    * In the above models I haven't discussed specific indexes to be added to tables, but these won't be forgotten. Indexes will be added where logical and should be tested using a large database with performance profiling.
  * '''Vessel acquisition''': If a user acquires a vessel, the vessel counts towards that user's vessel limit. In the future, limits may be by resources (e.g. diskspace) rather than number of vessels.
  * '''Vessel releasing''': Releasing a vessel means to clear the list of users with access to the node and to return the vessel credit to the user who had acquired the vessel. (The vessel may be reset, etc.)
  * '''Vessel multi-user access''': A vessel can be accessible to multiple users even though it is always acquired by a single user. Whether any user with access to the vessel can release it is not specified here and can be decided later. The simplest initial implementation is probably to allow any user with access the ability to release the vessel, so initial implementation will probably use that approach. (Adding additional users to a vessel may not be available through the UI for this version, but the functionality will be easy to implement.)
  * '''Sharing''': allowing other users to create vessels against your available resources is not re-incorporated in the design at this time.
