= Proposal -- Seattle's Unit Test Framework =

----
[[TOC(inline)]]
----

[[BR]]
== Abstract ==
----
The purpose of this proposal is to gather as much feedback as possible with respect to the new testing framework. Please feel free to add any comments or concerns at the bottom of the page.

[[BR]]
== Requirements ==
----
Before diving into examples and use cases, I would like to specify requirements, so that users have a better understanding of what the goals are. 

 * Above everything, writing a unit test module should be simple and obvious for new users.
 * For a small test modules simplicity should prevail over everything else. Having to prepare tests (using preparetests.py) before the execution is not a time effective solution. 
 * Test module should be able to have many small test cases and developer should be able to group them into test suites.
 * The framework should allow advanced users to perform non-trivial tests.
 * The framework should allow users to easily select what tests to run (whole module or specific test cases).
 * The framework back-end needs to be simple and extendible.

When translating requirements into objectives, we are faced with a non-trivial task, since some requirements are more important than others. As a result, advanced features are somewhat limited (for instance there is not support for test trees).

[[BR]]
=== Use Cases ===
----

The following examples are not meant to be complete test cases (or to follow standard testing practices) for some module, but instead, are there to demonstrate a specific feature.

=== Trivial Use-Case ===

Now, let us consider a trivial use case. We'll be designing a random number generator.

There are two methods defined:

{{{
#!python

def init_rng(seed):
def generate_next(rng):

}}}

We are testing for two conditions: 
 * Given two random number generators with different seeds, they should produce different outputs.
 * Sanity check -- input validation.

{{{
#!python

# Create a method that tests for a given objective.
def test_seed():
  seed1 = 32
  seed2 = 13

  rng1 = rng_init(seed1)
  rng2 = rng_init(seed2)

  next1 = generate_next(rng1)
  next2 = generate_next(rng2)

  # Make sure those two numbers are not the same.
  assertNotEqual(next1, next2)

def test_invalid_seed():
  assertRaises(BadInputException, rng_init("lol"))

# Register tests with our Unit Test Framework (UTF), by passing it
# a functor and a description.
registerTest(test_seed, "testing different seeds")
registerTest(test_invalid_seed, "testing invalid seed parameter")

}}}

When runing the test you should an output that looks something like this:

{{{
#!python

def init_rng(seed):
def generate_next(rng):

}}}

We are testing for two conditions: 
 * Given two random number generators with different seeds, they should produce different outputs.
 * Sanity check -- input validation.

{{{
#!python

$ testing random number generator module
$   testing different seeds                        [ ok ]
$   testing invalid seed parameter                 [ ok ]

}}}

This is a very simple scenario, and hopefully it illustrates some of the basics of our UTF.


=== Simple Use-Case ===

Another, more complicated example, would be IP <-> DNS converter.

There are two functions defined:

{{{
#!python

def to_ip(address):
def from_ip(ip):

}}}

Even though the logic behind this module is simple, testing is not. There are quite a few things we need to tested for: valid input, invalid input, boundary cases, etc. Therefore, when dealing with more sophisticated unit tests, it might be useful to separate test cases into test suites.

{{{
#!python

from_ip_bad_input = TestSuite()

def test_id_out_of_range():
  ...

def test_id_non_routable():
  ...

def test_id_zero():
  ...

roman_bad_input.addCases(test_id_out_of_range, test_id_non_routable, test_id_zero())
roman_bad_input.description("testing from ip to dns bad input")

from_ip_good_input = TestSuite()
...

to_ip_bad_input = TestSuite()
...

to_ip_good_input = TestSuite()
...

}}}

Please note that Test Suite feature is clunky, so it might be excluded from the implementation. There are ways around this problem, but it requires OO approach (which is not in compliance with project's coding guidelines).


=== Execution Monitor ===

All test files have to follow a strict naming convention: utf_test_<module name>_<optional>.py/mix. Therefore, if you want to create a test file for a random number generator module, the test file should be called: utf_test_rng.py

When running tests, a developer is presented with three different possibilities:
 * Run all tests for all modules:

{{{
#!python

$ utf.py --all

}}}

 * Run all tests for a specific module

{{{
#!python

$ utf.py --module rng

}}}

 * Run a specific test case or a test suite for a specific module

{{{
#!python

$ utf.py --module rng --case test_seed

}}}

[[BR]]
== API ==
----

=== Assert ===
  * assertTrue(expr[, msg])[[BR]]
    Signal a test failure if expr is true; the explanation for the error will be msg if given, otherwise it will be None.

  * assertFalse[[BR]]
    Signal a test failure if expr is false; the explanation for the error will be msg if given, otherwise it will be None.

  * assertEqual(first, second[, msg])[[BR]]
    Test that first and second are equal. If the values do not compare equal, the test will fail with the explanation given by msg, or None.

  * assertNotEqual[[BR]]
    Test that first and second are not equal. If the values do compare equal, the test will fail with the explanation given by msg, or None.

  * assertRaises[[BR]]
    Test that an exception is raised when callable is called with any positional or keyword arguments that are also passed to assertRaises(). The test passes if exception is raised, is an error if another exception is raised, or fails if no exception is raised. To catch any of a group of exceptions, a tuple containing the exception classes may be passed as exception.


[[BR]]
== Comments ==
----